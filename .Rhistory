# Requirement 1 -----------------------------------------------------------
# Create both "merged" and "merged/Inertial Signals" folders in one call.
# Merged data will be saved in these two folders, following the name patterns
# in "train" or "test" folders.
if (!file.exists("data/UCI HAR Dataset/merged/Inertial Signals")) dir.create("data/UCI HAR Dataset/merged/Inertial Signals", recursive = TRUE)
srcDirs <- c("data/UCI HAR Dataset/train", "data/UCI HAR Dataset/test")
targetDir <- "data/UCI HAR Dataset/merged"
# Since filenames follow a preset pattern, we can just use file names in "train" folder
# and derive file names in "test" and "merged" folders
files <- list.files(srcDirs[1], recursive = TRUE, include.dirs = FALSE)
for (file in files) {
f1 <- read.csv(paste(srcDirs[1], file, sep = "/"), header = FALSE)
testName <- gsub("_train", "_test", file)
f2 <- read.csv(paste(srcDirs[2], testName, sep = "/"), header = FALSE)
mergeName <- gsub("_train", "_merged", file)
write.table(f1, paste(targetDir, mergeName, sep = "/"), quote = FALSE, row.names = FALSE,
col.names = FALSE)
write.table(f2, paste(targetDir, mergeName, sep = "/"), quote = FALSE, row.names = FALSE,
col.names = FALSE, append = TRUE)
}
fixedWidth <- rep.int(16, 561)
features <- read.csv("data/UCI HAR Dataset/features.txt", sep = "", header = FALSE)
varNames <- features[, 2]
meanPos <- grepl("-mean()", varNames)
stdPos <- grepl("-std()", varNames)
namePos <- meanPos | stdPos
keptMeasurements <- data.frame()
names(keptMeasurements) <- varNames
keptMeasurements <- keptMeasurements[, namePos]
View(keptMeasurements)
View(keptMeasurements)
linesToSkip = 0;
linesToRead = 100;
linesRead = 0
while (linesRead < linesToRead) {
merged <- read.fwf("data/UCI HAR Dataset/merged/X_merged.txt", widths = fixedWidth, header = FALSE, n = linesToRead, skip = linesToSkip)
linesRead <- nrow(merged)
names(merged) <- varNames
subset <- merged[, namePos]
keptMeasurements <- rbind(keptMeasurements, subset)
linesToSkip <- linesToSkip + linesToRead
}
View(keptMeasurements)
keptMeasurements <- data.frame()
names(keptMeasurements) <- varNames
keptMeasurements <- keptMeasurements[, namePos]
# Reading the whole X_merged.txt file requires a huge amount of memory. Thus, we
# need to read records in small chunks.
linesToSkip = 0;
linesToRead = 100;
linesRead = 0
while (linesRead = linesToRead) {
merged <- read.fwf("data/UCI HAR Dataset/merged/X_merged.txt", widths = fixedWidth, header = FALSE, n = linesToRead, skip = linesToSkip)
linesRead <- nrow(merged)
names(merged) <- varNames
subset <- merged[, namePos]
keptMeasurements <- rbind(keptMeasurements, subset)
linesToSkip <- linesToSkip + linesToRead
}
keptMeasurements <- data.frame()
names(keptMeasurements) <- varNames
keptMeasurements <- keptMeasurements[, namePos]
# Reading the whole X_merged.txt file requires a huge amount of memory. Thus, we
# need to read records in small chunks.
linesToSkip = 0;
linesToRead = 100;
linesRead = linesToRead
while (linesRead = linesToRead) {
merged <- read.fwf("data/UCI HAR Dataset/merged/X_merged.txt", widths = fixedWidth, header = FALSE, n = linesToRead, skip = linesToSkip)
linesRead <- nrow(merged)
names(merged) <- varNames
subset <- merged[, namePos]
keptMeasurements <- rbind(keptMeasurements, subset)
linesToSkip <- linesToSkip + linesToRead
}
keptMeasurements <- data.frame()
names(keptMeasurements) <- varNames
keptMeasurements <- keptMeasurements[, namePos]
# Reading the whole X_merged.txt file requires a huge amount of memory. Thus, we
# need to read records in small chunks.
linesToSkip = 0;
linesToRead = 100;
linesRead = linesToRead
while (linesRead == linesToRead) {
merged <- read.fwf("data/UCI HAR Dataset/merged/X_merged.txt", widths = fixedWidth, header = FALSE, n = linesToRead, skip = linesToSkip)
linesRead <- nrow(merged)
names(merged) <- varNames
subset <- merged[, namePos]
keptMeasurements <- rbind(keptMeasurements, subset)
linesToSkip <- linesToSkip + linesToRead
}
fixedWidth <- rep.int(16, 561)
features <- read.csv("data/UCI HAR Dataset/features.txt", sep = "", header = FALSE)
varNames <- features[, 2]
meanPos <- grepl("-mean()", varNames)
stdPos <- grepl("-std()", varNames)
namePos <- meanPos | stdPos
keptMeasurements <- data.frame()
names(keptMeasurements) <- varNames
keptMeasurements <- keptMeasurements[, namePos]
# Reading the whole X_merged.txt file requires a huge amount of memory. Thus, we
# need to read records in small chunks.
linesToSkip = 0;
linesToRead = 1000;
linesRead = linesToRead
while (linesRead == linesToRead) {
merged <- read.fwf("data/UCI HAR Dataset/merged/X_merged.txt", widths = fixedWidth, header = FALSE, n = linesToRead, skip = linesToSkip)
linesRead <- nrow(merged)
names(merged) <- varNames
subset <- merged[, namePos]
keptMeasurements <- rbind(keptMeasurements, subset)
linesToSkip <- linesToSkip + linesRead
}
write.table(keptMeasurements, file = "data/UCI HAR Dataset/keptMeasurement.txt")
# Requirement 1 -----------------------------------------------------------
# Create both "merged" and "merged/Inertial Signals" folders in one call.
# Merged data will be saved in these two folders, following the name patterns
# in "train" or "test" folders.
if (!file.exists("data/processed/merged/Inertial Signals")) dir.create("data/UCI HAR Dataset/merged/Inertial Signals", recursive = TRUE)
# following the name patterns in "train" or "test" folders.
if (!file.exists("data/processed/merged/Inertial Signals")) dir.create("data/processed/merged/Inertial Signals", recursive = TRUE)
srcDirs <- c("data/UCI HAR Dataset/train", "data/UCI HAR Dataset/test")
targetDir <- "data/processed/merged"
# Since filenames follow a preset pattern, we can just use file names in "train" folder
# and derive file names in "test" and "merged" folders
files <- list.files(srcDirs[1], recursive = TRUE, include.dirs = FALSE)
for (file in files) {
f1 <- read.csv(paste(srcDirs[1], file, sep = "/"), header = FALSE)
testName <- gsub("_train", "_test", file)
f2 <- read.csv(paste(srcDirs[2], testName, sep = "/"), header = FALSE)
mergeName <- gsub("_train", "_merged", file)
write.table(f1, paste(targetDir, mergeName, sep = "/"), quote = FALSE, row.names = FALSE,
col.names = FALSE)
write.table(f2, paste(targetDir, mergeName, sep = "/"), quote = FALSE, row.names = FALSE,
col.names = FALSE, append = TRUE)
}
# Requirement 2 -----------------------------------------------------------
# Read in merged test data
# Looking into X_merged.txt reveals that it is of a fixed width format with 561 fields,
# each with 16 characters (numbers)
fixedWidth <- rep.int(16, 561)
features <- read.csv("data/UCI HAR Dataset/features.txt", sep = "", header = FALSE)
varNames <- features[, 2]
meanPos <- grepl("-mean()", varNames)
stdPos <- grepl("-std()", varNames)
namePos <- meanPos | stdPos
keptMeasurements <- data.frame()
names(keptMeasurements) <- varNames
keptMeasurements <- keptMeasurements[, namePos]
# Reading the whole X_merged.txt file requires a huge amount of memory. Thus, we
# need to read records in small chunks.
linesToSkip = 0;
linesToRead = 500;
linesRead = linesToRead
while (linesRead == linesToRead) {
merged <- read.fwf("data/processed/merged/X_merged.txt", widths = fixedWidth, header = FALSE, n = linesToRead, skip = linesToSkip)
linesRead <- nrow(merged)
names(merged) <- varNames
subset <- merged[, namePos]
keptMeasurements <- rbind(keptMeasurements, subset)
linesToSkip <- linesToSkip + linesRead
}
write.table(keptMeasurements, file = "data/processed/keptMeasurement.txt")
activities <- read.csv("data/UCI HAR Dataset/merged/y_merged.txt", header = FALSE)
activities <- read.csv("data/processed/y_merged.txt", header = FALSE)
activities <- read.csv("data/processed/merged/y_merged.txt", header = FALSE)
activity_labels <- read.csv("data/UCI HAR Dataset/activity_labels.txt", sep = "", header = FALSE)
activities$activity <- activity_labels[activities$V1, 2]
View(activities)
keptMeasurements <- read.table("data/processed/keptMeasurement.txt")
# Need to merge subject, activities, keptMeasurements
subject <- read.csv("data/UCI HAR Dataset/merged/subject_merged.txt", header = FALSE)
names(subject) <- c("Subject")
subject <- read.csv("data/processed/merged/subject_merged.txt", header = FALSE)
names(subject) <- c("Subject")
combined <- cbind(subject, activities[, "activity"], keptMeasurements)
View(combined)
combined <- cbind(subject, activities, keptMeasurements)
View(combined)
subject <- read.csv("data/processed/merged/subject_merged.txt", header = FALSE)
names(subject) <- c("subject")
combined <- cbind(subject, activities, keptMeasurements)
combined <- combined[, -2]
View(combined)
write.table(combined, file = "data/processed/combined.txt")
combined <- read.table("data/processed/combined.txt")
library(dplyr)
?summarize
?summarize_each
?summarise_each
?group_by
library(dplyr)
tidySet <- combined %>% group_by(subject, activity)
%>% summarise_each(mean)
tidySet <- combined %>% group_by(subject, activity) %>% summarise_each(mean)
tidySet <- combined %>% group_by(subject, activity) %>% summarise_each(funs(mean))
View(tidySet)
fixedWidth <- rep.int(16, 561)
features <- read.csv("data/UCI HAR Dataset/features.txt", sep = "", header = FALSE)
View(features)
varNames <- features[, 2]
varNames
varNames <- features[, 2]
meanPos <- grepl("-mean()", varNames)
stdPos <- grepl("-std()", varNames)
namePos <- meanPos | stdPos
keptMeasurements <- data.frame()
names(keptMeasurements) <- varNames
View(keptMeasurements)
View(keptMeasurements)
names(keptMeasurements) <- varNames
keptMeasurements <- keptMeasurements[, namePos]
fixedWidth <- rep.int(16, 561)
features <- read.csv("data/UCI HAR Dataset/features.txt", sep = "", header = FALSE)
varNames <- features[, 2]
meanPos <- grepl("-mean()", varNames)
stdPos <- grepl("-std()", varNames)
namePos <- meanPos | stdPos
keptMeasurements <- data.frame()
names(keptMeasurements) <- varNames
keptMeasurements <- keptMeasurements[, namePos]
# Reading the whole X_merged.txt file requires a huge amount of memory. Thus, we
# need to read records in small chunks.
linesToSkip = 0;
linesToRead = 500;
linesRead = linesToRead
#while (linesRead == linesToRead) {
merged <- read.fwf("data/processed/merged/X_merged.txt", widths = fixedWidth, header = FALSE, n = linesToRead, skip = linesToSkip)
linesRead <- nrow(merged)
names(merged) <- varNames
subset <- merged[, namePos]
View(subset)
keptMeasurements <- rbind(keptMeasurements, subset)
View(keptMeasurements)
# Since this takes time to generate, let's save it to a file
write.table(keptMeasurements, file = "data/processed/keptMeasurements.txt", )
View(keptMeasurements)
keptMeasurements2 <- read.table("data/processed/keptMeasurements.txt")
View(keptMeasurements2)
keptMeasurements2 <- read.table("data/processed/keptMeasurements.txt", as.is = TRUE)
View(keptMeasurements2)
keptMeasurements2 <- read.table("data/processed/keptMeasurements.txt", as.is = TRUE, colClasses = "character"
View(keptMeasurements2)
keptMeasurements2 <- read.table("data/processed/keptMeasurements.txt", as.is = TRUE, colClasses = "character")
View(keptMeasurements2)
keptMeasurements2 <- read.table("data/processed/keptMeasurements.txt", encoding='UTF-8')
View(keptMeasurements2)
keptMeasurements2 <- read.table("data/processed/keptMeasurements.txt", check.names=FALSE)
View(keptMeasurements2)
keptMeasurements2 <- read.table("data/processed/keptMeasurements.txt", check.names=TRUE)
View(keptMeasurements2)
FALSE
keptMeasurements2 <- read.table("data/processed/keptMeasurements.txt", check.names=FALSE)
View(keptMeasurements2)
fixedWidth <- rep.int(16, 561)
features <- read.csv("data/UCI HAR Dataset/features.txt", sep = "", header = FALSE)
varNames <- features[, 2]
meanPos <- grepl("-mean()", varNames)
stdPos <- grepl("-std()", varNames)
namePos <- meanPos | stdPos
keptMeasurements <- data.frame()
# Reading the whole X_merged.txt file requires a huge amount of memory. Thus, we
# need to read records in small chunks.
linesToSkip = 0;
linesToRead = 500;
linesRead = linesToRead
while (linesRead == linesToRead) {
merged <- read.fwf("data/processed/merged/X_merged.txt", widths = fixedWidth, header = FALSE, n = linesToRead, skip = linesToSkip)
linesRead <- nrow(merged)
names(merged) <- varNames
subset <- merged[, namePos]
keptMeasurements <- rbind(keptMeasurements, subset)
linesToSkip <- linesToSkip + linesRead
}
View(keptMeasurements)
# Since this takes time to generate, let's save it to a file
write.table(keptMeasurements, file = "data/processed/keptMeasurements.txt", )
# Requirement 3 ---------------------------------------------------------
activities <- read.csv("data/processed/merged/y_merged.txt", header = FALSE)
activity_labels <- read.csv("data/UCI HAR Dataset/activity_labels.txt", sep = "", header = FALSE)
activities$activity <- activity_labels[activities$V1, 2]
# Requirement 4 ---------------------------------------------------------
# Since we have applied varNames to read-in data in Requirement 2, the keptMeasurements
# has already descriptive variable names.
keptMeasurements <- read.table("data/processed/keptMeasurements.txt", check.names=FALSE)
View(keptMeasurements)
# Need to merge subject, activities, keptMeasurements
subject <- read.csv("data/processed/merged/subject_merged.txt", header = FALSE)
names(subject) <- c("subject")
combined <- cbind(subject, activities, keptMeasurements)
combined <- combined[, -2]
View(combined)
write.table(combined, file = "data/processed/combined.txt")
combined <- read.table("data/processed/combined.txt")
View(combined)
combined <- read.table("data/processed/combined.txt", check.names=FALSE)
View(combined)
library(dplyr)
tidySet <- combined %>% group_by(subject, activity) %>% summarise_each(funs(mean))
View(tidySet)
newColNames <- paste("Avg of", names(tidySet))
newColNames[1] <- names(tidySet)[1]
newColNames <- paste("avg of", names(tidySet))
newColNames[1] <- names(tidySet)[1]
newColNames[2] <- names(tidySet)[2]
names(tidySet) <- newColNames
View(tidySet)
write.table(tidySet, file = "data/processed/tidySet.txt", row.name=FALSE)
newColNames
newColNames
object_size(keptMeasurements)
size(keptMeasurements)
tidySet <- combined %>% group_by(subject, activity) %>% summarise_each(funs(mean))
combined <- read.table("data/processed/combined.txt", check.names=FALSE)
library(dplyr)
tidySet <- combined %>% group_by(subject, activity) %>% summarise_each(funs(mean))
View(tidySet)
